<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://nmd2k.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://nmd2k.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-05-13T06:54:03+00:00</updated><id>https://nmd2k.github.io/feed.xml</id><title type="html">blank</title><subtitle>:wave: Hi, my name is Dung (Dzung). I&apos;m a computer scientist working on AI for software systems. </subtitle><entry><title type="html">Mixture of expert explanation</title><link href="https://nmd2k.github.io/blog/2024/moe/" rel="alternate" type="text/html" title="Mixture of expert explanation"/><published>2024-03-23T00:00:00+00:00</published><updated>2024-03-23T00:00:00+00:00</updated><id>https://nmd2k.github.io/blog/2024/moe</id><content type="html" xml:base="https://nmd2k.github.io/blog/2024/moe/"><![CDATA[<p><strong><em>TLDR;</em></strong> In middle of the trend of scaling language model, Mixture of Expert (MoE) is a potential candidate to replace current scaling method and achieve comparable score to close-source LLMs like GPT-3.5, GPT-4, Claude, etc. Mixtral 8x7B is the latest open-source model from Mistral and took the spotlight on several open LLM benchmarks until this day (03/2024). In this blog, I will dig into the technique behind the success of MoE and try my best to give you all you need to know about MoE.</p> <h2 id="what-is-mixtral-8x7b">What is Mixtral 8x7B</h2> <p>In the LLMs marathon, Mixtral 8x7B leads the open-source benchmark in various chatbot categories. It boasts triple the votes of the 2nd open-source LLM and trails behind GPT-4, OpenAI’s strongest LLM, by ~ 45 points<d-footnote>https://openlm.ai/chatbot-arena/</d-footnote>. Mixtral 8x7B is the next version of Mixtral 7B, developed by the Mistral AI<d-footnote>https://mistral.ai/</d-footnote> team. The difference between the Mixtral 8x7B and other transformer models is the high-quality of the sparse mixture of expert layers (MoE) attachment.</p> <p>The table below presents the strength of Mixtral 8x7B when compared with LLaMA 2 (the latest open-source LLM from Meta) and GPT-3.5 (the most common LLM from OpenAI).</p> <div class="row mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/moe/mistral-report-480.webp 480w,/assets/img/posts/moe/mistral-report-800.webp 800w,/assets/img/posts/moe/mistral-report-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/moe/mistral-report.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Mixture of Experts report (source: mixtral-of-experts<d-footnote>https://mistral.ai/news/mixtral-of-experts/</d-footnote>) </div> <p>Mixtral 8x7B supports upto 32k tokens in term of context length, pre-train natively with 5 natural languages (i.e English, French, Italian, German and Spanish), releases under Apache 2.0 and allows people to commercialize it.</p> <p>Mixtral also proved to be good at coding, which achieved 40.2% on HumanEval. The development team also released an Instruct version of Mixtral, which has been optimized through fine-tuning and DPO to follow instructions given by the user.</p> <h2 id="mixture-of-expert">Mixture of Expert</h2> <p>Behind the success of mixtral 8x7B is mixture of expert (MoE) architecture. MoE bring to current transformers model the ability to speed up twice inferencing and pre-training time <d-cite key="du2022glam"></d-cite> due to the unique token path in expert layer, which only require certain nodes to work at each time. There are some recent work that found out MoE with instruction tuning is promising <d-cite key="shen2023mixtureofexperts"></d-cite>, make MoE is highly potential architecture in the near future.</p> <h3 id="definition-of-sparse-model">Definition of Sparse model</h3> <p>The sparse model is a combination of 2 parts: (1) a gate network (router) and (2) expert layers.</p> <ul> <li><strong>Sparse of MoE layer:</strong> Instead of using a normal feed-forward neural layer (FFN) inside transformer encoder or decoder, they replace it by a Sparse of MoE layer which contain a define number of experts, which in practice is actually FFN, but they can be also replace with any complex layer.</li> </ul> <div class="row mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/moe/moe-layer-480.webp 480w,/assets/img/posts/moe/moe-layer-800.webp 800w,/assets/img/posts/moe/moe-layer-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/moe/moe-layer.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Illustration of an MoE layer. For each input x, the router will only select one expert to perform computations. The choice is based on the output of the gating network (dotted line). The expert layer returns the output of the selected expert (gray box) multiplied by the route gate value (softmax of the gating function output). (Source: <d-cite key="chen2022understanding"></d-cite>) </div> <ul> <li><strong>Gate network or Router:</strong> A router will be used to determine which token will be sent to which expert. We can also send tokens to more than 1 expert. By the route system of gate neural, after training, each expert can specialize in a specific portion of the data. <d-cite key="chen2022understanding"></d-cite></li> </ul> <p>We can denote the MoE layer as follow:</p> \[y = \sum^{n}_{i=1}G(x_i)E_i\] <p>where $G$ present Gate neural network and $E_i$ indicate expert $i^{th}$. With $M$ is total number of expert layers, if $n$ is equal to whole expert set ($n=M$), this is called soft routing ($T_i=[N]$, at the moment $i$, tokens is sent to $N$ expert). But soft routing is not efficiency compare with dense model, therefor “switch routing” are replaced to save computation time and make the gating network sparse.</p> <p>Inside MoE layer contain $M$ expert, switch routing model will pick 1 expert from $M$ at each time $T_i=[1]=argmax_m({h_m(x; \Theta)})$.</p> <p>In practice, if $G$ is 0, the correspond expert operation is saving from computing. In a traditional setup, a softmax function can be added as a gating function (Wg is a trainable weight matrix multiplied by the input x):</p> \[G_{\sigma}(x)=Softmax(x.W_g)\] <p>The Gate network is so good so far, however, you might encouter with the question <em>“what if the number of training token is spent to each expert not equal?”</em>. Yes, it does. To purchase load-balancing for all experts, in Shazzer’s work <d-cite key="shazeer2017outrageously"></d-cite>, they added an additional trainable noise, i.e., Gaussian noice $H(x)$. And a “keep” function to store only the top k values and set the rest to $-\infty$ cause the gate values to equal 0, denoted as $KeepTopK()$.</p> \[H(x)_i=(x.W_g)_i+StandardNormal().Softplus((x.W_{noise})_i)\] \[KeepTopK(v,k)_i = \begin{cases}v1 &amp;\text{if } v_i \text{ is in the top } k \text{ elements of } v \\-\infty &amp; \text{other}\end{cases}\] <p>Therefore: $G(x) = Softmax(KeepTopK(H(x), k))$</p> <blockquote> <p class="block-warning">Since we introduced discontinuities in the output of the Gating function, however, this is fine. Don’t take my words, Shazzer said, “they observed this to be no problem in practice at all, and they trained the gating network by simple back-propagation, along with the rest of the model.”</p> </blockquote> <h3 id="addressing-challenges-of-moe">Addressing Challenges of MoE</h3> <h4 id="discontinuities-in-routing">Discontinuities in Routing</h4> <p>While sparse routing model saves computation and greatly reduces the inference times, it also causes discontinuities in routing<d-cite key="shazeer2017outrageously"></d-cite>. From the beginning, they added independently Gaussian noise $H(x)_i = (x.W_g)_i + StandardNormal()$, but in practice, they showed that even a small perturbation of the gating network outputs may change the router behavior drastically.</p> <p>From there, we can think of a additional loss function to allow the expert to receive roughly equal numbers of training example. However, when the training example come with a discrete quantity, it can not be used in back propagation. The problem can be solved by adding a smooth transition (smooth estimator $Load(X)$) between different routing behaviors (to make the router more stable).</p> <h4 id="balancing-expert-utilization">Balancing Expert Utilization</h4> <p>From the beginning, all experts initialize the same weights and training algorithm is the same. It is hard for new gating network learn right feature since every router is zero. Therefore, a mistake in training at the beginning may cause the expert to amplify that mistake.</p> <p>In Zixiang’s work <d-cite key="chen2022understanding"></d-cite>, they investigate the effectiveness of the initialization into expert divergence, they analyze the MoE layer between a stage called exploration stage where start at $t=0$ and ends at $T_1 = [\eta^-1\sigma_0^0.5]$, at each time one expert from $M$ experts is picked and with the gating network remains nearly unchanged. Even under the same treatment condition in each expert node, result shows after the exploration stage the experts become specialized to some specific task only based on the initialization.</p>]]></content><author><name>Dung Nguyen Manh</name></author><category term="research"/><summary type="html"><![CDATA[What's new behind Mixture of expert (MoE) mechanism? [Part 1]]]></summary></entry><entry><title type="html">Hội nghị đầu tiên - EMNLP”2023</title><link href="https://nmd2k.github.io/blog/2023/emnlp-2023-trip/" rel="alternate" type="text/html" title="Hội nghị đầu tiên - EMNLP”2023"/><published>2023-12-15T00:00:00+00:00</published><updated>2023-12-15T00:00:00+00:00</updated><id>https://nmd2k.github.io/blog/2023/emnlp-2023-trip</id><content type="html" xml:base="https://nmd2k.github.io/blog/2023/emnlp-2023-trip/"><![CDATA[<p>Chào mọi người, mình là Dũng. Mình vừa kết thúc hành trình đầu tiên của mình tại Singapore với hội nghị EMNLP. Quả thực mình đã gặp được nhiều may mắn trên hành trình thực hiện đề tài này, từ sự support hết mình của anh mentor, chương trình nơi mình đang công tác, đặc biệt là những người anh chị em, bạn bè của mình tại FPT.</p> <p>Ngẫm lại mới tháng 6 mình còn đang hì hục chạy thí nghiệm, tháng 7 nhờ mọi người trong team chỉnh sửa lại bài tại quán cafe Laika đường Láng (vì yếu tiếng anh quá nên phải nhờ mọi người hỗ trợ :&gt;) thì giờ đã và đang ở 1 đất nước xa lạ và tham dự hội nghị đầu tiên trong đời.</p> <h2 id="trước-hội-nghị">Trước hội nghị</h2> <p>Chưa từng tham gia hội nghị khiến mình luống cuống hơn bao giờ hết. Bài tụi mình chỉ được findings nên mình phải chủ động liên hệ workshop để có thể được present in-person. Tuy đã chuẩn bị từ sớm, nhưng cuối cùng mình lại trễ deadline poster lên xuống, sau đó còn phải email cho một số người bên BTC để xin họ chỗ present bài của mình. Cũng tại vì luống cuống quá mà sau đó bài mình phải present ở tận 2 workshop trùng giờ trùng ngày (nhưng may mà là có tận 2 authors cùng đến EMNLP lần này =)) nên trong cái rủi có cái vui)</p> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--getting-started"> <a href="/assets/img/emnlp2023/DSCF1888.jpg" data-pswp-width="5718" data-pswp-height="3812" data-cropped="true" target="_blank"> <img src="/assets/img/emnlp2023/DSCF1888_thumbnail.jpg" alt=""/> </a> </div> <p> </p> <h2 id="hội-nghị-chính">Hội nghị chính</h2> <p>Hội nghị EMNLP năm nay ngoài những nghiên cứu về NLP truyền thống, mình nhận thấy có phần trăm lớn nghiên cứu của năm nay tập trung làm về Large language model, cùng với việc đơn vị lớn như Google, Meta, Microsoft có một danh sách dài những paper về LLM được đăng tải tại EMNLP, mình nghĩ đây là biểu hiện từ sự quan tâm đặc biệt của cộng đồng academic lẫn industry về topic LLM và tương lai của NLP.</p> <div class="pswp-gallery pswp-gallery--single-column" id="gallery--getting-started"> <a href="/assets/img/emnlp2023/2023_1211_10015300.jpg" data-pswp-width="1776 " data-pswp-height=" 1184" data-cropped="true" target="_blank"> <img src="/assets/img/emnlp2023/2023_1211_10015300_thumbnail.jpg" alt=""/> </a> <a href="/assets/img/emnlp2023/2023_1211_10012900.jpg" data-pswp-width="1776 " data-pswp-height=" 1184" data-cropped="true" target="_blank"> <img src="/assets/img/emnlp2023/2023_1211_10012900_thumbnail.jpg" alt=""/> </a> <a href="/assets/img/emnlp2023/2023_1211_09475300.jpg" data-pswp-width="1776 " data-pswp-height=" 1184" data-cropped="true" target="_blank"> <img src="/assets/img/emnlp2023/2023_1211_09475300_thumbnail.jpg" alt=""/> </a> </div> <p> </p> <p>Các chủ đề được đón nhận về LLM bao gồm như discovering new LLM ability, hoặc các attempt đưa mô hình LLM cho natural language in general vào các bài toán cụ thể (yêu cầu knowledge domain). Vấn đề về scaling và boosting performance cho LLM cũng được đặc biệt quan tâm, nhiều giải pháp về phần cứng, giảm độ phức tạp tính toán, hay thay đổi về kiến trúc mô hình được trình bày nhằm thúc đẩy sức mạnh của LLM nói chung.</p> <p>Trong đó mình đặc biệt thấy keyword “Mixture of Expert” được xuất hiện nhiều lần, (kết hợp với 1 số mô hình áp dụng MoE gần đây đang thu hút sự chú ý). Bên lề, các survey, góc nhìn tổng quát về vấn đề đạo đức (ethical issues), kiểm soát thông tin giả (fact checking), đầu ra sai sự thật (hallucination), hay những phản ứng độc hại (toxicity) do LLM sinh ra cũng dành được nhiều quan tâm. Bên cạnh đó, chủ đề về evaluation LLM đặc biệt là khoản evaluate trong các domain cụ thể càng được quan tâm với số lượng lớn publication và benchmark dataset được release.</p> <h2 id="trải-nghiệm-bên-lề">Trải nghiệm bên lề</h2> <p>Ngoài 5 ngày biền biệt có mặt tại hội nghị, thật may mắn vì vẫn còn đủ thời gian tranh thủ đi ngắm đường xá Singapore và trải nghiệm ẩm thực nơi đây cùng bạn bè. Năm nay có lẽ cũng may mắn vì hội nghị tổ chức gần VN nên nhiều ace đồng nghiệp của mình cùng qua chung vui. Lần đầu xa nhà này còn nhiều bỡ ngỡ, tự nhận là tiếng anh của mình còn bập bẹ quá nên không tự tin để hỏi này nói kia được. May mắn là có anh mentor và các anh chị em đồng nghiệp cùng sang đây làm mình cảm giác như ở nhà.</p> <div class="gallery-container"> <div class="pswp-gallery custom-masonry-gallery" id="gallery--getting-started"> <a href="/assets/img/emnlp2023/DSCF1936.jpg" data-pswp-width="1654" data-pswp-height="1103" data-cropped="true" target="_blank"> <img src="/assets/img/emnlp2023/DSCF1936.jpg" alt=""/> </a> <a href="/assets/img/emnlp2023/2023_1211_09463300.jpg" data-pswp-width="1776" data-pswp-height="1184" data-cropped="true" target="_blank"> <img src="/assets/img/emnlp2023/2023_1211_09463300.jpg" alt=""/> </a> <a href="/assets/img/emnlp2023/2023_1211_10023900.jpg" data-pswp-width="1776" data-pswp-height="1184" data-cropped="true" target="_blank"> <img src="/assets/img/emnlp2023/2023_1211_10023900.jpg" alt=""/> </a> </div> </div> <p>Ở Singapore phương tiện công cộng phát triển rất hiện đại và tiện dụng, mình gần như có thể đi đến mọi nơi trong Singpore bằng hệ thống tàu điện (MRT) và xe bus. Những điểm trừ có lẽ với mình nói riêng là ở Sing phải đi bộ nhiều quá 😂. Đợt này mình còn mang độc mỗi đôi giày da, mỗi ngày đi bộ 5-10km làm đôi chân như rụng ra đó luôn. Tự hứa nếu có lần sau chắc chắn sẽ phải đi giày thể thao.</p> <h2 id="thư-viện-ảnh">Thư viện ảnh</h2> <p>Tuy rất gần về địa lý nhưng lại có khoảng cách rất rõ rệt giữa VN và nơi đây. Ngày xưa người Singapore cảm thấy Việt Nam rất giống Sing, nhưng giờ mình cảm thấy còn phải học hỏi nhiều về cách thức mọi thứ hoạt động ở nơi đây. Mong rằng trong tương lai sẽ còn nhiều cơ hội quay lại nơi đây.</p> <p>Thân.</p> <p><em>PS: Cảm ơn <strong>@Hiếu Đào</strong> đã cho mình mượn Fuji X100F trong chuyến đi lần này.</em></p> <div class="swiper-bounded"> <swiper-container keyboard="true" navigation="true" pagination="true" rewind="true" auto-height="true" zoom="true" zoom-max="3"> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/DSCF1982-480.webp 480w,/assets/img/emnlp2023/DSCF1982-800.webp 800w,/assets/img/emnlp2023/DSCF1982-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/DSCF1982.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption> Đảo Sentosa tuyệt đẹp. Dù Singapore là quốc đảo nhưng đảo Sentosa là một nơi đáng ghé thăm khi qua Sing. </figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/2023_1211_09475300-480.webp 480w,/assets/img/emnlp2023/2023_1211_09475300-800.webp 800w,/assets/img/emnlp2023/2023_1211_09475300-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/2023_1211_09475300.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Xe bus trên đảo Sentosa hoàn toàn miễn phí. Mình nói chuyện với các bác tài và họ nói ở Sing không có KPI cuốc nên họ cũng không vội chạy. Có lẽ 1 phần cũng vì ở Sing mình hiếm khi thấy tắc đường.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/2023_1211_09481500-480.webp 480w,/assets/img/emnlp2023/2023_1211_09481500-800.webp 800w,/assets/img/emnlp2023/2023_1211_09481500-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/2023_1211_09481500.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Ở Sing mọi người đi tay trái. Và mọi người chạy xe ... rất nhanh.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/2023_1211_09482100-480.webp 480w,/assets/img/emnlp2023/2023_1211_09482100-800.webp 800w,/assets/img/emnlp2023/2023_1211_09482100-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/2023_1211_09482100.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Nhưng luôn có lối cho người đi bộ và các phương tiện sẽ dừng từ rất xa cho người đi bộ qua đường.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/2023_1211_09391900-480.webp 480w,/assets/img/emnlp2023/2023_1211_09391900-800.webp 800w,/assets/img/emnlp2023/2023_1211_09391900-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/2023_1211_09391900.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Bãi biển ở Sentosa.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/2023_1211_10010500-480.webp 480w,/assets/img/emnlp2023/2023_1211_10010500-800.webp 800w,/assets/img/emnlp2023/2023_1211_10010500-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/2023_1211_10010500.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>"Siêu" trung tâm thương mại tại Marina Bay.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/2023_1211_10012900-480.webp 480w,/assets/img/emnlp2023/2023_1211_10012900-800.webp 800w,/assets/img/emnlp2023/2023_1211_10012900-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/2023_1211_10012900.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>"Siêu" trung tâm thương mại tại Marina Bay.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/2023_1211_10011700-480.webp 480w,/assets/img/emnlp2023/2023_1211_10011700-800.webp 800w,/assets/img/emnlp2023/2023_1211_10011700-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/2023_1211_10011700.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Apple Store bên trong quả cầu ở giữa đảo.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/DSCF1989-480.webp 480w,/assets/img/emnlp2023/DSCF1989-800.webp 800w,/assets/img/emnlp2023/DSCF1989-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/DSCF1989.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Sentosa world - nơi hội nghị chính diễn ra.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/2023_1211_10071000-480.webp 480w,/assets/img/emnlp2023/2023_1211_10071000-800.webp 800w,/assets/img/emnlp2023/2023_1211_10071000-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/2023_1211_10071000.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Sentosa world - nơi hội nghị chính diễn ra.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/DSCF2075-480.webp 480w,/assets/img/emnlp2023/DSCF2075-800.webp 800w,/assets/img/emnlp2023/DSCF2075-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/DSCF2075.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Bên trong hội nghị, khách mời của hội nghị đang trình bày.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/2023_1211_10043700-480.webp 480w,/assets/img/emnlp2023/2023_1211_10043700-800.webp 800w,/assets/img/emnlp2023/2023_1211_10043700-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/2023_1211_10043700.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Bên trong hội nghị, khách mời của hội nghị đang trình bày.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/2023_1211_10050900-480.webp 480w,/assets/img/emnlp2023/2023_1211_10050900-800.webp 800w,/assets/img/emnlp2023/2023_1211_10050900-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/2023_1211_10050900.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Bên trong hội nghị, khu vực poster.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/DSCF1995-480.webp 480w,/assets/img/emnlp2023/DSCF1995-800.webp 800w,/assets/img/emnlp2023/DSCF1995-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/DSCF1995.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Bên trong hội nghị, khu vực poster.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/DSCF2396-480.webp 480w,/assets/img/emnlp2023/DSCF2396-800.webp 800w,/assets/img/emnlp2023/DSCF2396-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/DSCF2396.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Đồ ăn được phục vụ trong ngày cuối tại hội nghị.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/DSCF2032-480.webp 480w,/assets/img/emnlp2023/DSCF2032-800.webp 800w,/assets/img/emnlp2023/DSCF2032-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/DSCF2032.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Cơn mưa bất chợt.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/DSCF2094-480.webp 480w,/assets/img/emnlp2023/DSCF2094-800.webp 800w,/assets/img/emnlp2023/DSCF2094-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/DSCF2094.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Hai nhà khoa học trẻ (trong hình là anh Nam - co-first author).</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/DSCF2112-480.webp 480w,/assets/img/emnlp2023/DSCF2112-800.webp 800w,/assets/img/emnlp2023/DSCF2112-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/DSCF2112.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Trên tàu điện (MRT).</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/DSCF1952-480.webp 480w,/assets/img/emnlp2023/DSCF1952-800.webp 800w,/assets/img/emnlp2023/DSCF1952-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/DSCF1952.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Đường phố sau cơn mưa.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/DSCF1949-480.webp 480w,/assets/img/emnlp2023/DSCF1949-800.webp 800w,/assets/img/emnlp2023/DSCF1949-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/DSCF1949.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Đường phố sau cơn mưa (Marina Bay từ xa).</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/DSCF1936-480.webp 480w,/assets/img/emnlp2023/DSCF1936-800.webp 800w,/assets/img/emnlp2023/DSCF1936-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/DSCF1936.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Món bak tuk teh anh Khánh mời ⭐️.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/DSCF1940-480.webp 480w,/assets/img/emnlp2023/DSCF1940-800.webp 800w,/assets/img/emnlp2023/DSCF1940-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/DSCF1940.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Món bak tuk teh anh Khánh mời ⭐️.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/DSCF2264-480.webp 480w,/assets/img/emnlp2023/DSCF2264-800.webp 800w,/assets/img/emnlp2023/DSCF2264-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/DSCF2264.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Đồ ăn ... Việt Nam tại Vivo city.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/DSCF2266-480.webp 480w,/assets/img/emnlp2023/DSCF2266-800.webp 800w,/assets/img/emnlp2023/DSCF2266-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/DSCF2266.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Đồ ăn ... Việt Nam tại Vivo city.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/2023_1211_09570800-480.webp 480w,/assets/img/emnlp2023/2023_1211_09570800-800.webp 800w,/assets/img/emnlp2023/2023_1211_09570800-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/2023_1211_09570800.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Singapore nổi tiếng với các khu nhà hàng (food court) nơi họ bán đa dạng 5-10 loại đồ ăn của các nước.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/2023_1205_19543500-480.webp 480w,/assets/img/emnlp2023/2023_1205_19543500-800.webp 800w,/assets/img/emnlp2023/2023_1205_19543500-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/2023_1205_19543500.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Singapore nổi tiếng với các khu nhà hàng (food court) nơi họ bán đa dạng 5-10 loại đồ ăn của các nước.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/2023_1211_09571500-480.webp 480w,/assets/img/emnlp2023/2023_1211_09571500-800.webp 800w,/assets/img/emnlp2023/2023_1211_09571500-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/2023_1211_09571500.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Nhưng cũng vì thế nếu chỉ trải nghiệm ở food court sẽ không cảm nhận được ẩm thực của Sing.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/2023_1211_10023900-480.webp 480w,/assets/img/emnlp2023/2023_1211_10023900-800.webp 800w,/assets/img/emnlp2023/2023_1211_10023900-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/2023_1211_10023900.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Nhưng cũng vì thế nếu chỉ trải nghiệm ở food court sẽ không cảm nhận được ẩm thực của Sing.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/DSCF1979-480.webp 480w,/assets/img/emnlp2023/DSCF1979-800.webp 800w,/assets/img/emnlp2023/DSCF1979-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/DSCF1979.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Phía sau One15 marina cove.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/DSCF1974-480.webp 480w,/assets/img/emnlp2023/DSCF1974-800.webp 800w,/assets/img/emnlp2023/DSCF1974-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/DSCF1974.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Singapore về đêm.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/2023_1211_10001900-480.webp 480w,/assets/img/emnlp2023/2023_1211_10001900-800.webp 800w,/assets/img/emnlp2023/2023_1211_10001900-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/2023_1211_10001900.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Khu canteen của Đại học Quản lý Singapore (SMU).</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/2023_1211_09383000-480.webp 480w,/assets/img/emnlp2023/2023_1211_09383000-800.webp 800w,/assets/img/emnlp2023/2023_1211_09383000-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/2023_1211_09383000.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Bên trong Universal trên đảo Sentosa.</figcaption> </figure> </swiper-slide> <swiper-slide> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emnlp2023/2023_1211_09380600-480.webp 480w,/assets/img/emnlp2023/2023_1211_09380600-800.webp 800w,/assets/img/emnlp2023/2023_1211_09380600-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/emnlp2023/2023_1211_09380600.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption>Bên trong Universal trên đảo Sentosa.</figcaption> </figure> </swiper-slide> </swiper-container> </div> <style>.gallery-container{width:80%;margin:2em auto 2em auto}.custom-masonry-gallery{display:grid;grid-template-columns:2fr 1fr;grid-template-rows:1fr 1fr;gap:5px;height:300px}.custom-masonry-gallery a:nth-child(1){grid-column:1 / 2;grid-row:1 / 3}.custom-masonry-gallery a:nth-child(2){grid-column:2 / 3;grid-row:1 / 2}.custom-masonry-gallery a:nth-child(3){grid-column:2 / 3;grid-row:2 / 3}.custom-masonry-gallery a{position:relative;width:100%;height:100%;overflow:hidden;display:block}.custom-masonry-gallery a img{width:100%;height:100%;object-fit:cover;display:block}.swiper-bounded{max-width:90vw;max-height:80vh;margin:2em auto;overflow:hidden;position:relative}swiper-container,.swiper-container{width:100%!important;height:100%!important;max-height:100%!important;box-sizing:border-box}swiper-slide,.swiper-slide{display:flex;align-items:center;justify-content:center;height:100%}swiper-slide figure{margin:0;width:100%;height:100%;display:flex;flex-direction:column;align-items:center}swiper-slide img{flex:1 1 auto;max-height:calc(80vh - 3em);width:auto;max-width:100%;object-fit:contain;display:block;margin:0 auto}swiper-slide figcaption{flex:0 0 auto;margin-top:.5em;text-align:left;color:#555;font-size:.85em;width:100%;background:rgba(255,255,255,0.7);font-style:italic}.swiper-bounded .swiper-pagination,swiper-container::part(pagination){position:static!important;margin-top:1em;text-align:center}</style>]]></content><author><name>Dung Nguyen Manh</name></author><category term="conference"/><category term="personal_blog"/><summary type="html"><![CDATA[Bài báo đầu tiên và những trải nghiệm cá nhân tại hội nghị]]></summary></entry><entry><title type="html">Alternative dataset for Code Understanding and Generation</title><link href="https://nmd2k.github.io/blog/2023/the-vault/" rel="alternate" type="text/html" title="Alternative dataset for Code Understanding and Generation"/><published>2023-08-19T21:00:00+00:00</published><updated>2023-08-19T21:00:00+00:00</updated><id>https://nmd2k.github.io/blog/2023/the-vault</id><content type="html" xml:base="https://nmd2k.github.io/blog/2023/the-vault/"><![CDATA[<p><strong><em>TLDR;</em></strong> The Vault is a multilingual code-text dataset with over 40 million pairs covering 10 popular programming languages. It is the largest corpus containing parallel code-text data. By building upon <strong><a href="https://huggingface.co/datasets/bigcode/the-stack">The Stack</a></strong>, a massive raw code sample collection, The Vault offers a comprehensive and high-quality resource for advancing research in code understanding and generation. The dataset also comes with an accessible toolkit for supporting the community and encouraging customize and improvement.</p> <h1 id="demand-for-large-scale-resource-parallel">Demand for large-scale resource parallel</h1> <p>The urgency for a massive parallel dataset in the domain of AI for code (AI4Code) stems from the increasing need to improve the performance of large language models (LLMs) for code generation and understanding. Despite the proliferation of open-source code repositories, we found out that existing code-text pair datasets, like CONCODE, FunCom, and CodeSearchNet, are significantly smaller than raw code datasets (CodeParrot Github, The Stack, The Pile, etc).</p> <p>In our experiment, we believe this size disparity has become a bottleneck for training AI4Code LLMs that rely heavily on fine-tuning pre-trained models using parallel code-text datasets. While models using non-parallel data or raw source code files are growing rapidly, those using code-text pair data (or bimodal) and chunked unimodal data (which only contain a certain level of code snippet) are constrained by data size.</p> <div class="row mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/the-vault/the-vault-1-480.webp 480w,/assets/img/posts/the-vault/the-vault-1-800.webp 800w,/assets/img/posts/the-vault/the-vault-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/the-vault/the-vault-1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Figure 1: A comparison table between current available function parallel dataset </div> <p>Furthermore, existing datasets like CoDesc, PyMT5, etc are limited to specific programming languages, underscoring the need for more diverse and larger datasets. Additionally, data quality plays a significant role in enhancing AI model performance. Therefore, the introduction of a large, high-quality dataset that spans multiple programming languages could greatly encourage the advancement of AI4Code LLMs.</p> <h1 id="what-does-the-vault-provide">What does The Vault provide?</h1> <p>CoDesc highlights the challenges faced by many tasks in the domain AI4Code, primarily the difficulty due to the lack of a standard noise removal method besides the lack of large standard datasets suitable for training deep neural models. To address those obstacles, we present The Vault, an extensive parallel dataset of code and docstring/comment. Our aim is to contribute to the community by providing a vast resource for training and evaluating natural language processing models related to code.</p> <p>Additionally, we also openly share our cleaning techniques and pipeline to extract data from raw code files, which involve careful design and analysis to enhance the data quality and optimize the performance in downstream tasks. When we design our cleaning rule, besides the 13 heuristics rule to eliminate un-informative data, we also apply a deep learning approach is utilized to refine the matching score between the parallel elements of The Vault.</p> <div class="row mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/the-vault/the-vault-2-480.webp 480w,/assets/img/posts/the-vault/the-vault-2-800.webp 800w,/assets/img/posts/the-vault/the-vault-2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/the-vault/the-vault-2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Our dataset and code are available to the community, and can easily access via Github and HuggingFace. The toolkit can support the community in various aspects of code extraction, parsing, filtering, and cleaning:</p> <p><strong>Key features:</strong></p> <ul> <li>Code parser: the package using <a href="https://tree-sitter.github.io/">tree-sitter</a> to provide an easy tool to extract function, class, and comment from source code.</li> <li>Docstring parser: Parse the docstring to acquire information such as summary comment, parameters, return type, docstring styles, etc.</li> <li>Filtering module: the module that integrates 13 rule-based methods to clean the docstring.</li> </ul> <h1 id="what-tasks-can-be-constructed-using-the-vault">What Tasks can be constructed using The Vault?</h1> <h3 id="code-summarization">Code summarization</h3> <p>Code summarization aims to generate human-readable descriptions which are meaningful and accurately describe the purpose or function of given code snippets. The input is a piece of code, and the output is a concise summary explaining its functionality.</p> <div class="row mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/the-vault/the-vault-3-480.webp 480w,/assets/img/posts/the-vault/the-vault-3-800.webp 800w,/assets/img/posts/the-vault/the-vault-3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/the-vault/the-vault-3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Traditionally, models are trained on parallel datasets containing code and corresponding comments or descriptions. However, these datasets can be noisy and limited, with descriptions that can be ambiguous, incomplete, or even misleading. In The Vault, we carefully design a cleaning method to capture all the informative sections of the docstring/description in order to boost model performance in the summarization task.</p> <h3 id="code-search">Code search</h3> <p>Code search is the task of retrieving relevant code snippets given a natural language query. The input is a query in natural language, and the output is a set of code snippets that satisfy the query. Models for this task are typically trained or fine-tuned using code and associated natural language descriptions from parallel datasets where both will be embedded into a vector space and compare similarities with each other.</p> <div class="row mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/the-vault/the-vault-4-480.webp 480w,/assets/img/posts/the-vault/the-vault-4-800.webp 800w,/assets/img/posts/the-vault/the-vault-4-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/the-vault/the-vault-4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>However, the effectiveness of a code search system heavily depends on the quality and diversity of its training data. Therefore, a well-curated, large, and diverse parallel dataset can significantly reduce this challenge and boost the model’s understanding of the relationship between code and natural language, resulting in better performance.</p> <h3 id="code-generation">Code generation</h3> <p>Code generation, or text-to-code, involves creating code based on a natural language description. The input is a description of a desired functionality, and the output is the code that performs that function. Models for this task are usually trained or fine-tuned on parallel datasets that contain pairs of natural language descriptions and their corresponding code. However, the existing datasets are often limited in their coverage of programming languages and can contain noisy or low-quality examples. A large, diverse, and high-quality parallel dataset can provide a broader range of examples and contexts, thereby improving the model’s ability to generate syntactically and semantically correct code across various languages and tasks.</p> <div class="row mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/the-vault/the-vault-5-480.webp 480w,/assets/img/posts/the-vault/the-vault-5-800.webp 800w,/assets/img/posts/the-vault/the-vault-5-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/the-vault/the-vault-5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h3 id="more-advanced-problems">More advanced problems</h3> <p>When extracting the Vault, our focus extends beyond extracting parallel elements from the source code. We make an effort to extract as much metadata as possible, including function/class information. The metadata obtained from The Vault dataset, such as parameter descriptions and types found in docstrings, can be utilized to generate more detailed and informative code summaries. By leveraging this information, models can provide insights into the purpose, expected inputs, and outputs of the suggested code, enhancing the summarization process.</p> <div class="row mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/the-vault/the-vault-6-480.webp 480w,/assets/img/posts/the-vault/the-vault-6-800.webp 800w,/assets/img/posts/the-vault/the-vault-6-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/the-vault/the-vault-6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>To extract docstring metadata, we have developed a docstring style parser capable of extracting information from each style. By leveraging the specific conventions and patterns used in various programming languages, models can gain a deeper understanding of these languages. This approach facilitates knowledge transfer and code comprehension across different programming paradigms, bridging the gap between them.</p> <div class="row mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/the-vault/the-vault-7-480.webp 480w,/assets/img/posts/the-vault/the-vault-7-800.webp 800w,/assets/img/posts/the-vault/the-vault-7-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/the-vault/the-vault-7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Figure 2: Example of 6 docstring styles </div> <h1 id="data-characteristics-inside-the-vault">Data characteristics inside The Vault</h1> <p>In this exciting new dataset, we have delved into the world of programming languages to uncover some fascinating insights.</p> <h2 id="comparison-with-existing-benchmarks">Comparison with Existing Benchmarks</h2> <p>The Vault stands out from existing datasets due to its extensive coverage of programming languages and its substantial size. The comparison is illustrated in the figure below.</p> <div class="row mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/the-vault/the-vault-8-480.webp 480w,/assets/img/posts/the-vault/the-vault-8-800.webp 800w,/assets/img/posts/the-vault/the-vault-8-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/the-vault/the-vault-8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> Figure 3: Function set comparison properties with other available datasets </div> <p>After deduplication, we achieve over 34M pairs, which still significantly surpasses the scale of existing datasets. We split the data into 3 training sets (small, medium, and full), a validation set, and a test set.</p> <div class="row mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/the-vault/the-vault-9-480.webp 480w,/assets/img/posts/the-vault/the-vault-9-800.webp 800w,/assets/img/posts/the-vault/the-vault-9-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/the-vault/the-vault-9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h2 id="data-characteristics-distributions">Data characteristics distributions</h2> <div class="row mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/the-vault/the-vault-10-480.webp 480w,/assets/img/posts/the-vault/the-vault-10-800.webp 800w,/assets/img/posts/the-vault/the-vault-10-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/the-vault/the-vault-10.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>The table above provides information about the dataset, highlighting the prevalence of Python and Java programming languages and the abundance of tokens within the dataset. Python and Java are the dominant languages in the dataset, indicating their popularity and widespread usage. The dataset encompasses a significant number of tokens, indicating a substantial amount of code and associated text.</p> <p>In analyzing each sample, the average token length for code hovers around 100 tokens, while docstrings exhibit remarkable brevity with an average of only 15 tokens.</p> <h2 id="docstring-styles">Docstring styles</h2> <p>Alongside typical docstrings that provide brief descriptions of the source code, many adhere to formatting and style conventions like Google, Jsdoc, and reST styles, among others.</p> <p>With our carefully designed toolkit, we have harnessed the power to parse these docstrings and extract valuable metadata, all while supporting a remarkable 11 prevalent docstring styles.</p> <p>Through extensive statistical analysis, we have gained insights into the prevalence of styled docstrings within the larger code-text dataset. It is fascinating to note that these styled docstrings constitute only a fraction of the entire corpus. However, this seemingly small fraction opens up a world of possibilities for advanced research. Imagine the potential of controlling docstring style during generation or crafting nuanced explanations for function parameters. This rich dataset provides a fertile ground for exploring and tackling these complex challenges.</p> <h1 id="unleash-your-curiosity-and-explore-further">Unleash Your Curiosity and Explore Further</h1> <p>We encourage you to explore the concepts and ideas presented in this blog post in more detail. You can find additional information through the resources provided below.</p> <p><strong><em>Paper</em>:</strong> More details about The Vault can be found in our <a href="https://arxiv.org/abs/2305.06156">research paper</a>.</p> <p><strong><em>GitHub</em>:</strong> Check out our source code and toolkit <a href="https://github.com/FSoft-AI4Code/TheVault/">HERE</a>.</p> <p><strong><em>Huggingface:</em></strong> Check out The Vault on <a href="https://huggingface.co/datasets/Fsoft-AIC/the-vault-function">HuggingFace hub</a>.</p> <p><strong><em>Feedback or Questions:</em></strong> Contact us at <a href="mailto:support.ailab@fpt.com">support.ailab@fpt.com</a>.</p> <h1 id="acknowledgments">Acknowledgments</h1> <p>We are grateful to have the support of the FPT Software AI Center in funding this project. For more details about our organization and its initiatives, please visit <strong><a href="https://www.fpt-aicenter.com/about/">https://www.fpt-aicenter.com/about/</a></strong>.</p>]]></content><author><name></name></author><category term="research"/><summary type="html"><![CDATA[A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation]]></summary></entry></feed>